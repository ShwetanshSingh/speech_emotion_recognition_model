{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca992dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8191ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravdess = \"./datasets/Ravdess/\"\n",
    "Crema = \"./datasets/Crema/\"\n",
    "Tess = \"./datasets/Tess/\"\n",
    "Savee = \"./datasets/Savee/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e3e86",
   "metadata": {},
   "source": [
    "### Ravdess Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60930c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "file_path = []\n",
    "file_emotion = []\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess+dir)\n",
    "    for file in actor:\n",
    "        part = file.split(\".\")[0]\n",
    "        part = part.split(\"-\")\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess+dir+\"/\"+file)\n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=[\"Emotions\"])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=[\"Path\"])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Ravdess_df.Emotions.replace({1:\"neutral\", 2:\"calm\",3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff8889",
   "metadata": {},
   "source": [
    "### Crema Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a6b7f",
   "metadata": {},
   "source": [
    "### Tess Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d6914",
   "metadata": {},
   "source": [
    "### Savee Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6548029",
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81489f9d",
   "metadata": {},
   "source": [
    "### Create Dataframe from all four dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e7eab8",
   "metadata": {},
   "source": [
    "### Data Visualization and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90407cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(data_path.Emotions, palette=\"pastel\")\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0e0ca",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(data_path.Path, data_path.Emotions):\n",
    "    X.append(path)\n",
    "    Y.append(emotion)\n",
    "\n",
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77bb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = OneHotEncoder()\n",
    "# Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48116e82",
   "metadata": {},
   "source": [
    "### Save Test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e952c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_df = pd.DataFrame(x_test, columns=[\"Path\"])\n",
    "# y_test_df = pd.DataFrame(y_test, columns=encoder.categories_[0])\n",
    "# test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "# test_df.to_csv(\"./datasets/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c473d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.DataFrame(x_test, columns=[\"Path\"])\n",
    "y_test_df = pd.DataFrame(y_test, columns=[\"Emotion\"])\n",
    "test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "test_df.to_csv(\"./datasets/test_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabb2c7",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n",
    "\n",
    "# taking any example and checking for techniques.\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9847f3",
   "metadata": {},
   "source": [
    "We use only noise and stretch, copying the steps from kaggle notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af63b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(x_train, y_train):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced920c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.to_csv(\"./datasets/train_dataset.csv\", index=False)\n",
    "# Features.to_excel(\"./datasets/train_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9a96a",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = pd.read_csv(\"./datasets/test_dataset.csv\")\n",
    "# y = test_dataset[[\"Emotion\"]]\n",
    "# x = test_dataset.drop(\"Emotion\", axis=1)\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558599df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_test(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res = extract_features(data)\n",
    "    result = np.array(res)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = [], []\n",
    "for path, emotion in zip(x.Path, y.Emotion):\n",
    "    features = get_features_from_test(path)\n",
    "    x_test.append(features)\n",
    "    y_test.append(emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7603b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"./datasets/train_dataset.csv\")\n",
    "\n",
    "# Separate features (X) and labels (Y)\n",
    "Y = train_dataset[['labels']].copy()\n",
    "# Y.columns = ['Emotion']  # Rename the column to match our convention\n",
    "X = train_dataset.drop('labels', axis=1)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"./datasets/test_dataset.csv\")\n",
    "\n",
    "y_test = test_dataset[[\"Emotion\"]].copy()\n",
    "x_test = test_dataset.drop(\"Emotion\", axis=1)\n",
    "x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab32bca",
   "metadata": {},
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1, 1)).toarray()\n",
    "# y_test = encoder.fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe90701",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = encoder.fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35169254",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed1aed",
   "metadata": {},
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d6a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.fit_transform(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, axis=2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84960efe",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8750495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\", input_shape=(X.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = \"same\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = \"same\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=8, activation=\"softmax\"))\n",
    "model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\" , metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b283dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor=\"loss\", factor=0.4, verbose=0, patience=2, min_lr=10e-8)\n",
    "history = model.fit(X, Y, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513ca84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
